---
title: "Calculating the Scaling Rate"
format: html
---

### Function Scaling For Each Grid 

```{python}
import pandas as pd
import numpy as np
import xarray as xr
import statsmodels.api as sm
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import warnings
from scipy.stats import linregress
import geopandas as gpd

def calculate_dewpoint(temp, humidity):
    A = 17.27
    B = 237.7
    alpha = ((A * temp) / (B + temp)) + np.log(humidity/100.0)
    return (B * alpha) / (A - alpha)

def calculate_bins(series):
    series_range = series.max() - series.min()
    return int(series_range / 0.5)

def grid_scaling(pr_dir, tas_dir, hur_dir, start_year, stop_year, method=None):
    years_list = [str(year) for year in range(start_year, stop_year)]
    
    interp_pr, interp_tas, interp_hur, interp_tdew = {}, {}, {}, {}

    for year in years_list: 
        file_name = f"{year}.csv"
        # pr
        file_pr = pd.read_csv(pr_dir + "\\" + file_name)
        file_pr = file_pr[file_pr.lat > -60]
        # tas
        file_tas = pd.read_csv(tas_dir+ "\\" + file_name)
        file_tas = file_tas[file_tas.lat > -60]
        # hur
        file_hur = pd.read_csv(hur_dir+ "\\" + file_name)
        file_hur = file_hur[file_hur.lat > -60]
        interp_pr[year], interp_tas[year], interp_hur[year] = file_pr, file_tas, file_hur 
    
    # Calculate Dewpoint temperature 

    warnings.filterwarnings(action='ignore')

    interp_tdew = {}

    for key in interp_tas.keys():
        tas = interp_tas[key]
        hur = interp_hur[key]
        tdew = pd.DataFrame()
        tdew[["lat", "lon"]] = tas[["lat", "lon"]]
        for day in tas.columns[2:]:
            tdew[day] = calculate_dewpoint(tas[day], hur[day])
        interp_tdew[key] = tdew 
    
    # Combine pr and tdew 
    pr = pd.concat([df.set_index(["lat", "lon"]) for df in list(interp_pr.values())], axis=1).reset_index()
    pr['lat_lon'] = pr['lat'].astype(str) + ',' + pr['lon'].astype(str)
    pr = pr.drop(['lat', 'lon'], axis=1)
    pr_long = pd.melt(pr, id_vars=['lat_lon'], var_name='date', value_name='pr')
    tdew = pd.concat([df.set_index(["lat", "lon"]) for df in list(interp_tas.values())], axis=1).reset_index()
    tdew['lat_lon'] = tdew['lat'].astype(str) + ',' +  tdew['lon'].astype(str)
    tdew = tdew.drop(['lat', 'lon'], axis=1)
    tdew_long = pd.melt(tdew, id_vars=['lat_lon'], var_name='date', value_name='tdew')
    pr_long["tdew"] = tdew_long['tdew'].values

    # get Wet-day 

    pr_long = pr_long[pr_long.pr > 0.1]

    result = {}
    plot = {}

    if method == "quantile_regression" or method is None:

        qr = pr_long.groupby('lat_lon').apply(lambda group: sm.QuantReg(np.log(group['pr']), sm.add_constant(group['tdew'])).fit(q = 0.99))

        dfs = []
        for group_key, group_result in qr.items():
            lat_lon = group_key
            slope_coefficient = group_result.params['tdew']  
            df = pd.DataFrame({'code': [lat_lon], 'slope_coefficient': [slope_coefficient]})
            dfs.append(df)
        result_qr = pd.concat(dfs, ignore_index=True)
        result_qr["Scaling"] = 100*(np.e**result_qr["slope_coefficient"] - 1)
        result_qr[['lat', 'lon']] = result_qr['code'].str.split(',', expand=True)
        result_qr['lat'] = pd.to_numeric(result_qr['lat'])
        result_qr['lon'] = pd.to_numeric(result_qr['lon'])
        result_qr = result_qr[["lat", "lon", 'Scaling']]
        

        # plotting 
        
        result['quantile_regression'] = result_qr
        plot["Quantile_Regression plot"] =  visualize_result(result_qr, method = "Quantile Regression")

    if method == "binning_p" or method is None:
        
        df = pr_long.copy()
        nbin = 30 
        df['bin'] = df.groupby('lat_lon')['tdew'].transform(lambda x: pd.qcut(x, q=nbin, labels=False, duplicates='drop'))
        dfs = df.drop(['date'], axis = 1)
        bm = dfs.groupby(['lat_lon', 'bin']).agg({'pr': lambda x: x.quantile(0.99), 'tdew': 'mean'}).reset_index()
        bm['log_p_99'] = bm['pr'].apply(lambda x: 0 if x <= 0 else 1 if x == 1 else np.log(x))
        bm.columns = ['lat_lon', 'bin', 'p_99_pr', 'mean_tdew', 'log_p99']
        slopes = []

        for lat_lon, group in bm.groupby('lat_lon'):
            slope, _, _, _, _ = linregress(group['mean_tdew'], group['log_p99'])
            slopes.append({'lat_lon': lat_lon, 'slope': slope})
        result_bm = pd.DataFrame(slopes)
        result_bm["Scaling"] = 100*(np.e**result_bm["slope"] - 1)
        result_bm[['lat', 'lon']] = result_bm['lat_lon'].str.split(',', expand=True)
        result_bm['lat'] = pd.to_numeric(result_bm['lat'])
        result_bm['lon'] = pd.to_numeric(result_bm['lon'])
        result_bm = result_bm[["lat", "lon", 'Scaling']]
        

        # plotting 
        result["binning_p"] = result_bm
        plot["Binning Equal Data Point plot"] =  visualize_result(result_bm, method = "Binning Equal Data Point")

    if method == "binning_w" or method is None:

        df = pr_long.copy()
        df['bin'] = df.groupby('lat_lon')['tdew'].transform(lambda x: pd.cut(x, bins=calculate_bins(x), labels=False, include_lowest=True))
        dfs = df.drop(['date'], axis=1)
        bm_width = dfs.groupby(['lat_lon', 'bin']).agg({'pr': lambda x: x.quantile(0.99), 'tdew': 'mean'}).reset_index()
        bm_width['log_p_99'] = bm_width['pr'].apply(lambda x: 0 if x <= 0 else 1 if x == 1 else np.log(x))
        bm_width.columns = ['lat_lon', 'bin', 'p_99_pr', 'mean_tdew', 'log_p99']

        # Calculate slopes
        slopes = []
        for lat_lon, group in bm_width.groupby('lat_lon'):
            slope, _, _, _, _ = linregress(group['mean_tdew'], group['log_p99'])
            slopes.append({'lat_lon': lat_lon, 'slope': slope})
    
        # Create DataFrame for results
        result_bm_width = pd.DataFrame(slopes)
        result_bm_width["Scaling"] = 100*(np.e**result_bm_width["slope"] - 1)
        result_bm_width[['lat', 'lon']] = result_bm_width['lat_lon'].str.split(',', expand=True)
        result_bm_width['lat'] = pd.to_numeric(result_bm_width['lat'])
        result_bm_width['lon'] = pd.to_numeric(result_bm_width['lon'])
        result_bm_width = result_bm_width[["lat", "lon", 'Scaling']]
        
        # Plotting 
        result["binning_w"] = result_bm_width
        plot["Binning Equal Width plot"] = visualize_result(result_bm_width, method = "Binning Equal Bin Width")

    df = pd.concat([df.assign(source=source) for source, df in result.items()])

    # Reset the index
    df.reset_index(drop=True, inplace=True)

    return result, df, plot
```

#### Usage 

```{python}
res = pd.DataFrame()
for year in range(2041, 2061):
    r,d,p = grid_scaling(pr_dir = "D:\Min\Review GCM\CanESM5\SSP585\Interpolated\Pr",
             tas_dir = "D:\Min\Review GCM\CanESM5\SSP585\Interpolated\Tas",
             hur_dir = "D:\Min\Review GCM\CanESM5\SSP585\Interpolated\Hurs", 
             start_year =  year,
             stop_year = year+20)
    d = d.rename(columns = {"Scaling": str(year+20)})
    print("done: ", year)
    if year == 2041: 
        res = d 
    else: res = pd.merge(res,d , on = ["lat", "lon", "source"], how = 'inner')
```

### Function Scaling For Each Region 

```{python}
import pandas as pd
import numpy as np
import xarray as xr
import statsmodels.api as sm
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import warnings
from scipy.stats import linregress
import geopandas as gpd

def calculate_dewpoint(temp, humidity):
    A = 17.27
    B = 237.7
    alpha = ((A * temp) / (B + temp)) + np.log(humidity/100.0)
    return (B * alpha) / (A - alpha)

def process_data(interp_data, region_data):
    for year, df in interp_data.items():
        df = pd.merge(df, region_data, on=["lat", "lon"], how="inner")
        last_column = df.pop(df.columns[-1])
        df.insert(0, last_column.name, last_column)
        df = df.drop(["lat", "lon"], axis=1)
        interp_data[year] = df

def calculate_bins(series):
    series_range = series.max() - series.min()
    return int(series_range / 1)


def region_scaling(pr_dir, tas_dir, hur_dir, start_year, stop_year, region,  method = None):
    years_list = [str(year) for year in range(start_year, stop_year+1)]
    interp_pr, interp_tas, interp_hur, interp_tdew = {}, {}, {}, {}

    for year in years_list: 
        file_name = f"{year}.csv"
        # pr
        file_pr = pd.read_csv(pr_dir + "\\" + file_name)
        file_pr = file_pr[file_pr.lat > -60]
        # tas
        file_tas = pd.read_csv(tas_dir+ "\\" + file_name)
        file_tas = file_tas[file_tas.lat > -60]
        # hur
        file_hur = pd.read_csv(hur_dir+ "\\" + file_name)
        file_hur = file_hur[file_hur.lat > -60]
        interp_pr[year], interp_tas[year], interp_hur[year] = file_pr, file_tas, file_hur 
    
    # Calculate Dewpoint temperature 

    warnings.filterwarnings(action='ignore')

    interp_tdew = {}

    for key in interp_tas.keys():
        tas = interp_tas[key]
        hur = interp_hur[key]
        tdew = pd.DataFrame()
        tdew[["lat", "lon"]] = tas[["lat", "lon"]]
        for day in tas.columns[2:]:
            tdew[day] = calculate_dewpoint(tas[day], hur[day])
        interp_tdew[key] = tdew 

    if region == "ar6":
        grouped = pd.read_csv("D:\Min\Review GCM\Region and Location\Grouping_Region_AR6.csv")[["lat", "lon", "code"]]
    elif region == "srex":
        grouped = pd.read_csv("D:\Min\Review GCM\Region and Location\Grouping_Region_SREX.csv")[["lat", "lon", "code"]]

    # Match with Pr and Tdew dict 
        
    process_data(interp_pr, grouped)
    process_data(interp_tdew, grouped)

    # Combine tdew and Pr 

    pr = pd.concat([df.set_index(["code"]) for df in list(interp_pr.values())], axis=1).reset_index()
    pr_long = pd.melt(pr, id_vars=['code'], var_name='date', value_name='pr')
    tdew  = pd.concat([df.set_index(['code']) for df in list(interp_tdew.values())], axis=1).reset_index()
    tdew_long = pd.melt(tdew, id_vars=['code'], var_name='date', value_name='tdew')
    pr_long["tdew"] = tdew_long['tdew'].values

    # get Wet-day 

    pr_long = pr_long[pr_long.pr > 0.1]
    
    result = {}

    if method == "quantile_regression" or method is None: 

        qr =  pr_long.groupby('code').apply(lambda group: sm.QuantReg(np.log(group['pr']), sm.add_constant(group[['tdew']])).fit(q=0.99))

        dfs = []

        for group_key, group_result in qr.items():
            code = group_key
            slope_coefficient = group_result.params["tdew"]
            df = pd.DataFrame({'code': [code], 'slope_coefficient': slope_coefficient})
            dfs.append(df)
        
        result_qr = pd.concat(dfs, ignore_index=True)

        result_qr["Scaling"] =  100*(np.e**result_qr["slope_coefficient"] - 1)
        result_qr = result_qr[["code", "Scaling"]]

        # Add to result dict 
        result["quantile_regression"] = result_qr

    if method == "binning_data_point" or method is None:
        df = pr_long.copy()
        n_bins = 30
        df["bin"] = df.groupby('code')['tdew'].transform(lambda x: pd.qcut(x, q=n_bins, labels=False, duplicates='drop'))
        dfs = df.drop(['date'], axis = 1)

        bm = dfs.groupby(['code', 'bin']).agg({'pr': lambda x: x.quantile(0.99), 'tdew': 'mean'}).reset_index()
        bm['log_p_99'] = bm['pr'].apply(lambda x: 0 if x <= 0 else 1 if x == 1 else np.log(x))
        bm.columns = ['code', 'bin', 'p_99_pr', 'mean_tdew', 'log_p99']

        slopes = []

        for code, group in bm.groupby('code'):

            slope, _, _, _, _ = linregress(group['mean_tdew'], group['log_p99'])

            slopes.append({'code': code, 'slope': slope})

        result_bm = pd.DataFrame(slopes)

        result_bm["Scaling"] = 100*(np.e**result_bm["slope"] - 1)
        result_bm = result_bm[["code", "Scaling"]]

        # Add to result dict 
        result["binning_equal_data"] = result_bm
        

    if method == "binning_equal_width" or method is None:
        df = pr_long.copy()
        df["bin"] = df.groupby('code')['tdew'].transform(lambda x: pd.cut(x, bins=calculate_bins(x), labels=False, include_lowest=True))

        dfs = df.drop(['date'], axis = 1)

        bm_width =  dfs.groupby(['code', 'bin']).agg({'pr': lambda x: x.quantile(0.99), 'tdew': 'mean'}).reset_index()
        bm_width['log_p_99'] = bm_width['pr'].apply(lambda x: 0 if x <= 0 else 1 if x == 1 else np.log(x))
        bm_width.columns = ['code', 'bin', 'p_99_pr', 'mean_tdew', 'log_p99']

        slopes = []

        for code, group in bm_width.groupby('code'):

            slope, _, _, _, _ = linregress(group['mean_tdew'], group['log_p99'])

            slopes.append({'code': code, 'slope': slope})

        result_bm_width = pd.DataFrame(slopes)

        result_bm_width["Scaling"] = 100*(np.e**result_bm_width["slope"] - 1)

        result_bm_width = result_bm_width[["code", "Scaling"]]

    # Add to result dict 
        
        result["binning_equal_width"] = result_bm_width

    df = pd.concat([df.assign(source=source) for source, df in result.items()])
    # Reset the index
    df.reset_index(drop=True, inplace=True)

    return result, df
```

#### Usage

```{python}
acess585 = pd.DataFrame()
for year in range(2041, 2071):
    r,d = region_scaling(pr_dir = "D:\Min\Review GCM\ACCESS-CM2\Interpolated\Pr",
             tas_dir = "D:\Min\Review GCM\ACCESS-CM2\Interpolated\Tas",
             hur_dir = "D:\Min\Review GCM\ACCESS-CM2\Interpolated\Hurs", 
             start_year =  year,
             stop_year = year+20,
             region = "srex")
    d = d.rename(columns = {"Scaling": str(year+20)})
    print("done: ", year)
    if year == 2041: 
        acess585 = d 
    else: acess585 = pd.merge(acess585,d , on = ["code", "source"], how = 'inner')
```